\section{Analysis and Discussion}

Our results emphasize that EA2 is more diverse than EA1. Moreover, EA2 performs better when the algorithms were trained on the first enemy group, while EA1 performs better when being trained on the second enemy group. The t-test did not show that the two EAs significantly differ from each other in terms of performance. In comparison to the baseline paper \cite{Arajo2016EvolvingAG}, Table \ref{table:bestind} highlights that our algorithm is performing worse than the ones tested by \cite{Arajo2016EvolvingAG}. While our algorithm only consistently beats 4 enemies with an average maximum player life of 47.2, the proposed NEAT algorithm beats all enemies consistently with a maximum player life of 94.

One possible reason for EA2 having higher values for the first enemy group could be the higher diversity of EA2, which allows it to explore the search space more generally than EA1, which has a high selection pressure. Even though EA2 has lower average fitness values due to its higher diversity acceptance, it performs better than EA1 at a generalist task when facing the group of enemies with diverse behaviour. Based on the gain values, it can be deducted that the first enemy group is harder to beat than the second one and hence might give an advantage to an EA with higher diversity. Potentially, a diverse training set might be favourable to train a diverse EA. 

For the second group of enemies, EA1 has better values than EA2 for both maximum and average values. Therefore, we can observe that the EA1 performs better at training for a specific task, where the environment and the behaviour of the enemies do not differ as much as for enemy group 1. Finally, because of its higher diversity, EA2 has a larger variance than EA1, which make the population converge in a small interval of fitness values.

Taken together, our results shed light on how a training and testing set could be crucial for picking the diversity of an EA and emphasise that yet again, an EA has to be tailored individually to a problem. We reason that our training sets might have been too different in diversity and therefore lead to inconsistent results when being tested against the same enemies. Therefore, for our optimization problem, an EA using the comma survivor selection strategy, with a balanced approach between diversity and quality, cannot be seen as superior to an EA using an age-based survivor selection strategy with higher diversity. However, it is important to underline the inconsistent results between the two training enemy groups. 