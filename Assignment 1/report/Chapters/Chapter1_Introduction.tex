\section{Introduction}

Evolutionary Algorithms (EA) are based on biological evolution, leading to the creation of an artificial population that evolves over several generations. In order to maximize the fitness of a population, the methods of selection, recombination, and mutation are used. Moreover, EAs are not reliant on function gradient information where optima can be found in a discrete, non-linear and non-deterministic process.\par

One crucial aspect in designing a high-quality EA is to increase population diversity with variation of chromosomes. Diversity ensures a sufficient novelty of the population over the time of generations, and therefore avoids local optima and premature convergence. However, increasing diversity might come at the cost of quality within a population due to negative changes in the chromosomes and a resulting lower fitness. Hence, a dynamic combination between high diversity that escapes local optima and low diversity that ensures progress by fine-tuning the solutions specifically tailored to individual chromosomes might give the best optimization results.\par

One mutation method that was found to dynamically change diversity is the self-adaptive mutation \cite{Teo2006SelfadaptiveMF}. This method is adjusting the mutation specifically to the individual gene, leading to a tailored mutation for each chromosome. In comparison, the Gaussian mutation changes chromosomes by a random value from a draw of the Gaussian distribution around the mean 0 and a standard deviation of sigma. Based on the difference of these methods, this paper aims to answer the research question whether an EA with a self-adaptive mutation method can be seen as superior in terms of fitness performance in comparison to a standard EA using a standard Gaussian mutation. In order to investigate the research question, we compare two EAs with different mutation methods in the EvoMan environment \cite{defranca2020evoman} using the evolutionary computation framework DEAP \cite{DEAP_JMLR2012}.\par

EvoMan \cite{defranca2020evoman} is a video game computational intelligence framework in which an agent, equipped with an arm cannon, fights against different robots in several environments. Movements of the agent include moving to the right or left, shoot, jump, and interrupt the jump to fall to the ground. The enemy robots are equipped with different weapons and movements in order to hurt the agent. Both, agent and robot, start with 100 energy points that decrease once they are hit by the otherâ€™s projectiles. The game ends when one of the energy levels turns zero. For our experiment, the agent, controlled by the EAs, fights against the enemies \empg{Airman}, \emph{Metalman}, and \emph{Quickman}.\par